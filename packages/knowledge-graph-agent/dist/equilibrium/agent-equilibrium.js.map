{"version":3,"file":"agent-equilibrium.js","sources":["../../src/equilibrium/agent-equilibrium.ts"],"sourcesContent":["/**\n * Agent Equilibrium Selector (SPEC-006a)\n *\n * Implements Nash equilibrium-based agent selection to replace heuristic\n * capability-matching in CoordinatorAgent. Uses game-theoretic principles\n * where agents adjust their participation levels based on task fit and\n * competition from other agents with similar capabilities.\n *\n * @module equilibrium/agent-equilibrium\n */\n\nimport { AgentType } from '../agents/types.js';\nimport { type AgentInfo } from '../agents/planner-agent.js';\n\n// ============================================================================\n// Types and Interfaces\n// ============================================================================\n\n/**\n * Agent participation in a task allocation game\n */\nexport interface AgentParticipation {\n  /** Agent identifier */\n  agentId: string;\n  /** Agent type */\n  agentType: AgentType;\n  /** Participation level (0-1), equilibrium outcome */\n  participationLevel: number;\n  /** Effectiveness score for the task (0-1) */\n  effectivenessScore: number;\n  /** Penalty for overlapping with other agents */\n  redundancyPenalty: number;\n  /** Net utility from participation */\n  utility: number;\n}\n\n/**\n * Configuration for equilibrium computation\n */\nexport interface EquilibriumConfig {\n  /** Learning rate for gradient updates (default: 0.1) */\n  learningRate: number;\n  /** Maximum iterations before stopping (default: 100) */\n  maxIterations: number;\n  /** Convergence threshold for participation changes (default: 0.001) */\n  convergenceThreshold: number;\n  /** Minimum participation level before collapsing to 0 (default: 0.01) */\n  minParticipation: number;\n}\n\n/**\n * Task definition for equilibrium selection\n */\nexport interface Task {\n  /** Unique task identifier */\n  id: string;\n  /** Task description */\n  description: string;\n  /** Required capabilities for the task */\n  requiredCapabilities: string[];\n  /** Task priority */\n  priority: 'low' | 'medium' | 'high' | 'critical';\n  /** Task complexity (0-1) */\n  complexity: number;\n}\n\n/**\n * Equilibrium computation result\n */\nexport interface EquilibriumResult {\n  /** Participating agents sorted by participation level */\n  participants: AgentParticipation[];\n  /** Number of iterations to converge */\n  iterations: number;\n  /** Whether equilibrium was reached */\n  converged: boolean;\n  /** Total utility at equilibrium */\n  totalUtility: number;\n}\n\n// ============================================================================\n// Agent Equilibrium Selector\n// ============================================================================\n\n/**\n * AgentEquilibriumSelector\n *\n * Computes Nash equilibrium for agent selection using iterative gradient\n * updates. Each agent adjusts its participation level based on:\n * - Effectiveness: How well the agent matches the task requirements\n * - Competition: Overlap with other participating agents\n * - Utility: Net benefit from participating\n *\n * Dominated agents (those with lower effectiveness and high overlap)\n * naturally collapse to zero participation, leaving only the most\n * suitable agents.\n *\n * @example\n * ```typescript\n * const selector = new AgentEquilibriumSelector();\n * const selected = await selector.selectTopAgents(task, agents, 3);\n * ```\n */\nexport class AgentEquilibriumSelector {\n  private config: EquilibriumConfig;\n  private participations: Map<string, AgentParticipation>;\n  private iterationHistory: Array<{ iteration: number; totalUtility: number }>;\n\n  constructor(config: Partial<EquilibriumConfig> = {}) {\n    this.config = {\n      learningRate: 0.1,\n      maxIterations: 100,\n      convergenceThreshold: 0.001,\n      minParticipation: 0.01,\n      ...config,\n    };\n    this.participations = new Map();\n    this.iterationHistory = [];\n  }\n\n  // ==========================================================================\n  // Public API\n  // ==========================================================================\n\n  /**\n   * Find Nash equilibrium for agent selection\n   *\n   * Each agent adjusts participation based on task match and competition.\n   * Returns agents with positive participation, sorted by level.\n   *\n   * @param task - The task to allocate\n   * @param availableAgents - Pool of available agents\n   * @returns Agents with positive participation at equilibrium\n   */\n  async findEquilibrium(\n    task: Task,\n    availableAgents: AgentInfo[]\n  ): Promise<AgentParticipation[]> {\n    // Reset state for new computation\n    this.iterationHistory = [];\n\n    // Handle edge cases\n    if (availableAgents.length === 0) {\n      return [];\n    }\n\n    if (availableAgents.length === 1) {\n      // Single agent case - no competition\n      const agent = availableAgents[0];\n      const effectiveness = this.calculateEffectiveness(agent, task);\n      const participation: AgentParticipation = {\n        agentId: agent.id,\n        agentType: agent.type,\n        participationLevel: 1.0,\n        effectivenessScore: effectiveness,\n        redundancyPenalty: 0,\n        utility: effectiveness,\n      };\n      this.participations.set(agent.id, participation);\n      return [participation];\n    }\n\n    // 1. Initialize participation levels uniformly\n    this.initializeParticipations(availableAgents, task);\n\n    // 2. Iterate until convergence or max iterations\n    let converged = false;\n    let iteration = 0;\n\n    for (iteration = 0; iteration < this.config.maxIterations; iteration++) {\n      const prevState = this.snapshotParticipations();\n\n      // Update each agent's participation\n      for (const agent of availableAgents) {\n        this.updateAgentParticipation(agent, task, availableAgents);\n      }\n\n      // Normalize participation levels to prevent runaway values\n      this.normalizeParticipations();\n\n      // Check convergence\n      if (this.hasConverged(prevState)) {\n        converged = true;\n        break;\n      }\n\n      // Record history\n      this.iterationHistory.push({\n        iteration,\n        totalUtility: this.calculateTotalUtility(),\n      });\n    }\n\n    // Log convergence info\n    if (!converged) {\n      console.debug(\n        `Equilibrium did not converge after ${this.config.maxIterations} iterations`\n      );\n    }\n\n    // 3. Return agents with positive participation, sorted by level\n    return [...this.participations.values()]\n      .filter(p => p.participationLevel > 0)\n      .sort((a, b) => b.participationLevel - a.participationLevel);\n  }\n\n  /**\n   * Select top N agents based on equilibrium\n   *\n   * @param task - The task to allocate\n   * @param availableAgents - Pool of available agents\n   * @param n - Maximum number of agents to select\n   * @returns Selected agents (may be less than n if not enough qualify)\n   */\n  async selectTopAgents(\n    task: Task,\n    availableAgents: AgentInfo[],\n    n: number\n  ): Promise<AgentInfo[]> {\n    const equilibrium = await this.findEquilibrium(task, availableAgents);\n    return equilibrium\n      .slice(0, n)\n      .map(p => availableAgents.find(a => a.id === p.agentId)!)\n      .filter(Boolean);\n  }\n\n  /**\n   * Get iteration history for analysis/debugging\n   */\n  getIterationHistory(): Array<{ iteration: number; totalUtility: number }> {\n    return [...this.iterationHistory];\n  }\n\n  /**\n   * Get current participation state\n   */\n  getParticipations(): Map<string, AgentParticipation> {\n    return new Map(this.participations);\n  }\n\n  /**\n   * Get configuration\n   */\n  getConfig(): EquilibriumConfig {\n    return { ...this.config };\n  }\n\n  // ==========================================================================\n  // Initialization\n  // ==========================================================================\n\n  /**\n   * Initialize participation levels uniformly across agents\n   */\n  private initializeParticipations(agents: AgentInfo[], task: Task): void {\n    this.participations.clear();\n    const uniformLevel = 1.0 / agents.length;\n\n    for (const agent of agents) {\n      const effectiveness = this.calculateEffectiveness(agent, task);\n      this.participations.set(agent.id, {\n        agentId: agent.id,\n        agentType: agent.type,\n        participationLevel: uniformLevel,\n        effectivenessScore: effectiveness,\n        redundancyPenalty: 0,\n        utility: 0,\n      });\n    }\n  }\n\n  // ==========================================================================\n  // Gradient Update\n  // ==========================================================================\n\n  /**\n   * Update a single agent's participation based on game dynamics\n   */\n  private updateAgentParticipation(\n    agent: AgentInfo,\n    task: Task,\n    allAgents: AgentInfo[]\n  ): void {\n    const participation = this.participations.get(agent.id);\n    if (!participation) return;\n\n    // Calculate utility: effectiveness * participation (returns from participating)\n    const utility =\n      participation.effectivenessScore * participation.participationLevel;\n\n    // Calculate competition from similar agents (costs from competition)\n    const competition = this.calculateCompetition(agent, allAgents);\n\n    // Calculate redundancy penalty\n    participation.redundancyPenalty = competition * 0.5;\n\n    // Net utility (marginal benefit of participating)\n    const netUtility = utility - participation.redundancyPenalty;\n    participation.utility = netUtility;\n\n    // Gradient update toward equilibrium\n    // Agent increases participation if net utility exceeds competition\n    // Agent decreases participation if competition dominates\n    const delta = this.config.learningRate * (netUtility - competition);\n\n    participation.participationLevel = Math.max(\n      0,\n      Math.min(1, participation.participationLevel + delta)\n    );\n\n    // Dominated agents collapse to zero (below threshold)\n    if (participation.participationLevel < this.config.minParticipation) {\n      participation.participationLevel = 0;\n    }\n  }\n\n  /**\n   * Normalize participation levels to sum to at most 1\n   * This prevents runaway accumulation\n   */\n  private normalizeParticipations(): void {\n    const total = [...this.participations.values()].reduce(\n      (sum, p) => sum + p.participationLevel,\n      0\n    );\n\n    if (total > 1) {\n      for (const p of this.participations.values()) {\n        p.participationLevel = p.participationLevel / total;\n      }\n    }\n  }\n\n  // ==========================================================================\n  // Effectiveness Calculation\n  // ==========================================================================\n\n  /**\n   * Calculate how effective an agent is for a given task\n   *\n   * Combines:\n   * - Capability match (70% weight)\n   * - Type boost for task keywords (30% weight)\n   */\n  calculateEffectiveness(agent: AgentInfo, task: Task): number {\n    // Score based on capability match\n    const requiredCaps = new Set(task.requiredCapabilities);\n    const agentCaps = new Set(agent.capabilities || []);\n\n    let matchCount = 0;\n    for (const cap of requiredCaps) {\n      if (agentCaps.has(cap)) matchCount++;\n    }\n\n    const capabilityMatch =\n      requiredCaps.size > 0 ? matchCount / requiredCaps.size : 0.5;\n\n    // Boost for agent type matching task keywords\n    const typeBoost = this.getTypeBoost(agent.type, task);\n\n    // Combine with weights\n    return capabilityMatch * 0.7 + typeBoost * 0.3;\n  }\n\n  /**\n   * Get type-based boost for matching task keywords\n   */\n  getTypeBoost(agentType: AgentType, task: Task): number {\n    const desc = task.description.toLowerCase();\n\n    // Map keywords to relevant agent types\n    const boostMap: Record<string, AgentType[]> = {\n      review: [AgentType.REVIEWER],\n      test: [AgentType.TESTER],\n      code: [AgentType.CODER],\n      implement: [AgentType.CODER],\n      document: [AgentType.DOCUMENTER],\n      plan: [AgentType.PLANNER],\n      optimize: [AgentType.OPTIMIZER],\n      research: [AgentType.RESEARCHER],\n      analyze: [AgentType.ANALYST],\n      architect: [AgentType.ARCHITECT],\n      design: [AgentType.ARCHITECT],\n      coordinate: [AgentType.COORDINATOR],\n    };\n\n    for (const [keyword, types] of Object.entries(boostMap)) {\n      if (desc.includes(keyword) && types.includes(agentType)) {\n        return 1.0;\n      }\n    }\n\n    // Default low boost for non-matching types\n    return 0.3;\n  }\n\n  // ==========================================================================\n  // Competition Calculation\n  // ==========================================================================\n\n  /**\n   * Calculate competition pressure from other agents\n   *\n   * Competition increases with:\n   * - Number of other agents with overlapping capabilities\n   * - Participation levels of overlapping agents\n   */\n  calculateCompetition(agent: AgentInfo, allAgents: AgentInfo[]): number {\n    let competition = 0;\n\n    for (const other of allAgents) {\n      if (other.id === agent.id) continue;\n\n      const overlap = this.capabilityOverlap(agent, other);\n      const otherParticipation = this.participations.get(other.id);\n      if (otherParticipation) {\n        competition += overlap * otherParticipation.participationLevel;\n      }\n    }\n\n    return competition;\n  }\n\n  /**\n   * Calculate capability overlap between two agents\n   *\n   * Returns a value from 0 (no overlap) to 1 (complete overlap)\n   */\n  capabilityOverlap(a: AgentInfo, b: AgentInfo): number {\n    const capsA = new Set(a.capabilities || []);\n    const capsB = new Set(b.capabilities || []);\n\n    if (capsA.size === 0 || capsB.size === 0) {\n      // No capabilities defined - use type similarity as proxy\n      return a.type === b.type ? 0.8 : 0.2;\n    }\n\n    let overlap = 0;\n    for (const cap of capsA) {\n      if (capsB.has(cap)) overlap++;\n    }\n\n    // Jaccard-like coefficient using max instead of union\n    return overlap / Math.max(capsA.size, capsB.size);\n  }\n\n  // ==========================================================================\n  // Convergence Detection\n  // ==========================================================================\n\n  /**\n   * Create snapshot of current participation levels\n   */\n  private snapshotParticipations(): Map<string, number> {\n    const snapshot = new Map<string, number>();\n    for (const [id, p] of this.participations) {\n      snapshot.set(id, p.participationLevel);\n    }\n    return snapshot;\n  }\n\n  /**\n   * Check if participation levels have converged\n   */\n  private hasConverged(prevState: Map<string, number>): boolean {\n    let maxDelta = 0;\n\n    for (const [id, p] of this.participations) {\n      const prev = prevState.get(id) ?? 0;\n      const delta = Math.abs(p.participationLevel - prev);\n      maxDelta = Math.max(maxDelta, delta);\n    }\n\n    return maxDelta < this.config.convergenceThreshold;\n  }\n\n  // ==========================================================================\n  // Utility Calculation\n  // ==========================================================================\n\n  /**\n   * Calculate total utility across all agents\n   */\n  calculateTotalUtility(): number {\n    return [...this.participations.values()].reduce(\n      (sum, p) => sum + p.utility,\n      0\n    );\n  }\n}\n\n// ============================================================================\n// Factory Functions\n// ============================================================================\n\n/**\n * Create a new AgentEquilibriumSelector with optional configuration\n */\nexport function createAgentEquilibriumSelector(\n  config?: Partial<EquilibriumConfig>\n): AgentEquilibriumSelector {\n  return new AgentEquilibriumSelector(config);\n}\n\n/**\n * Create a task for equilibrium selection\n */\nexport function createEquilibriumTask(\n  id: string,\n  description: string,\n  options: {\n    requiredCapabilities?: string[];\n    priority?: 'low' | 'medium' | 'high' | 'critical';\n    complexity?: number;\n  } = {}\n): Task {\n  return {\n    id,\n    description,\n    requiredCapabilities: options.requiredCapabilities ?? [],\n    priority: options.priority ?? 'medium',\n    complexity: options.complexity ?? 0.5,\n  };\n}\n"],"names":[],"mappings":";AAuGO,MAAM,yBAAyB;AAAA,EAC5B;AAAA,EACA;AAAA,EACA;AAAA,EAER,YAAY,SAAqC,IAAI;AACnD,SAAK,SAAS;AAAA,MACZ,cAAc;AAAA,MACd,eAAe;AAAA,MACf,sBAAsB;AAAA,MACtB,kBAAkB;AAAA,MAClB,GAAG;AAAA,IAAA;AAEL,SAAK,qCAAqB,IAAA;AAC1B,SAAK,mBAAmB,CAAA;AAAA,EAC1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAgBA,MAAM,gBACJ,MACA,iBAC+B;AAE/B,SAAK,mBAAmB,CAAA;AAGxB,QAAI,gBAAgB,WAAW,GAAG;AAChC,aAAO,CAAA;AAAA,IACT;AAEA,QAAI,gBAAgB,WAAW,GAAG;AAEhC,YAAM,QAAQ,gBAAgB,CAAC;AAC/B,YAAM,gBAAgB,KAAK,uBAAuB,OAAO,IAAI;AAC7D,YAAM,gBAAoC;AAAA,QACxC,SAAS,MAAM;AAAA,QACf,WAAW,MAAM;AAAA,QACjB,oBAAoB;AAAA,QACpB,oBAAoB;AAAA,QACpB,mBAAmB;AAAA,QACnB,SAAS;AAAA,MAAA;AAEX,WAAK,eAAe,IAAI,MAAM,IAAI,aAAa;AAC/C,aAAO,CAAC,aAAa;AAAA,IACvB;AAGA,SAAK,yBAAyB,iBAAiB,IAAI;AAGnD,QAAI,YAAY;AAChB,QAAI,YAAY;AAEhB,SAAK,YAAY,GAAG,YAAY,KAAK,OAAO,eAAe,aAAa;AACtE,YAAM,YAAY,KAAK,uBAAA;AAGvB,iBAAW,SAAS,iBAAiB;AACnC,aAAK,yBAAyB,OAAO,MAAM,eAAe;AAAA,MAC5D;AAGA,WAAK,wBAAA;AAGL,UAAI,KAAK,aAAa,SAAS,GAAG;AAChC,oBAAY;AACZ;AAAA,MACF;AAGA,WAAK,iBAAiB,KAAK;AAAA,QACzB;AAAA,QACA,cAAc,KAAK,sBAAA;AAAA,MAAsB,CAC1C;AAAA,IACH;AAGA,QAAI,CAAC,WAAW;AACd,cAAQ;AAAA,QACN,sCAAsC,KAAK,OAAO,aAAa;AAAA,MAAA;AAAA,IAEnE;AAGA,WAAO,CAAC,GAAG,KAAK,eAAe,QAAQ,EACpC,OAAO,CAAA,MAAK,EAAE,qBAAqB,CAAC,EACpC,KAAK,CAAC,GAAG,MAAM,EAAE,qBAAqB,EAAE,kBAAkB;AAAA,EAC/D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,gBACJ,MACA,iBACA,GACsB;AACtB,UAAM,cAAc,MAAM,KAAK,gBAAgB,MAAM,eAAe;AACpE,WAAO,YACJ,MAAM,GAAG,CAAC,EACV,IAAI,CAAA,MAAK,gBAAgB,KAAK,CAAA,MAAK,EAAE,OAAO,EAAE,OAAO,CAAE,EACvD,OAAO,OAAO;AAAA,EACnB;AAAA;AAAA;AAAA;AAAA,EAKA,sBAA0E;AACxE,WAAO,CAAC,GAAG,KAAK,gBAAgB;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA,EAKA,oBAAqD;AACnD,WAAO,IAAI,IAAI,KAAK,cAAc;AAAA,EACpC;AAAA;AAAA;AAAA;AAAA,EAKA,YAA+B;AAC7B,WAAO,EAAE,GAAG,KAAK,OAAA;AAAA,EACnB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASQ,yBAAyB,QAAqB,MAAkB;AACtE,SAAK,eAAe,MAAA;AACpB,UAAM,eAAe,IAAM,OAAO;AAElC,eAAW,SAAS,QAAQ;AAC1B,YAAM,gBAAgB,KAAK,uBAAuB,OAAO,IAAI;AAC7D,WAAK,eAAe,IAAI,MAAM,IAAI;AAAA,QAChC,SAAS,MAAM;AAAA,QACf,WAAW,MAAM;AAAA,QACjB,oBAAoB;AAAA,QACpB,oBAAoB;AAAA,QACpB,mBAAmB;AAAA,QACnB,SAAS;AAAA,MAAA,CACV;AAAA,IACH;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASQ,yBACN,OACA,MACA,WACM;AACN,UAAM,gBAAgB,KAAK,eAAe,IAAI,MAAM,EAAE;AACtD,QAAI,CAAC,cAAe;AAGpB,UAAM,UACJ,cAAc,qBAAqB,cAAc;AAGnD,UAAM,cAAc,KAAK,qBAAqB,OAAO,SAAS;AAG9D,kBAAc,oBAAoB,cAAc;AAGhD,UAAM,aAAa,UAAU,cAAc;AAC3C,kBAAc,UAAU;AAKxB,UAAM,QAAQ,KAAK,OAAO,gBAAgB,aAAa;AAEvD,kBAAc,qBAAqB,KAAK;AAAA,MACtC;AAAA,MACA,KAAK,IAAI,GAAG,cAAc,qBAAqB,KAAK;AAAA,IAAA;AAItD,QAAI,cAAc,qBAAqB,KAAK,OAAO,kBAAkB;AACnE,oBAAc,qBAAqB;AAAA,IACrC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,0BAAgC;AACtC,UAAM,QAAQ,CAAC,GAAG,KAAK,eAAe,OAAA,CAAQ,EAAE;AAAA,MAC9C,CAAC,KAAK,MAAM,MAAM,EAAE;AAAA,MACpB;AAAA,IAAA;AAGF,QAAI,QAAQ,GAAG;AACb,iBAAW,KAAK,KAAK,eAAe,OAAA,GAAU;AAC5C,UAAE,qBAAqB,EAAE,qBAAqB;AAAA,MAChD;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaA,uBAAuB,OAAkB,MAAoB;AAE3D,UAAM,eAAe,IAAI,IAAI,KAAK,oBAAoB;AACtD,UAAM,YAAY,IAAI,IAAI,MAAM,gBAAgB,CAAA,CAAE;AAElD,QAAI,aAAa;AACjB,eAAW,OAAO,cAAc;AAC9B,UAAI,UAAU,IAAI,GAAG,EAAG;AAAA,IAC1B;AAEA,UAAM,kBACJ,aAAa,OAAO,IAAI,aAAa,aAAa,OAAO;AAG3D,UAAM,YAAY,KAAK,aAAa,MAAM,MAAM,IAAI;AAGpD,WAAO,kBAAkB,MAAM,YAAY;AAAA,EAC7C;AAAA;AAAA;AAAA;AAAA,EAKA,aAAa,WAAsB,MAAoB;AACrD,UAAM,OAAO,KAAK,YAAY,YAAA;AAG9B,UAAM,WAAwC;AAAA,MAC5C,QAAQ,CAAC,UAAU,QAAQ;AAAA,MAC3B,MAAM,CAAC,UAAU,MAAM;AAAA,MACvB,MAAM,CAAC,UAAU,KAAK;AAAA,MACtB,WAAW,CAAC,UAAU,KAAK;AAAA,MAC3B,UAAU,CAAC,UAAU,UAAU;AAAA,MAC/B,MAAM,CAAC,UAAU,OAAO;AAAA,MACxB,UAAU,CAAC,UAAU,SAAS;AAAA,MAC9B,UAAU,CAAC,UAAU,UAAU;AAAA,MAC/B,SAAS,CAAC,UAAU,OAAO;AAAA,MAC3B,WAAW,CAAC,UAAU,SAAS;AAAA,MAC/B,QAAQ,CAAC,UAAU,SAAS;AAAA,MAC5B,YAAY,CAAC,UAAU,WAAW;AAAA,IAAA;AAGpC,eAAW,CAAC,SAAS,KAAK,KAAK,OAAO,QAAQ,QAAQ,GAAG;AACvD,UAAI,KAAK,SAAS,OAAO,KAAK,MAAM,SAAS,SAAS,GAAG;AACvD,eAAO;AAAA,MACT;AAAA,IACF;AAGA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaA,qBAAqB,OAAkB,WAAgC;AACrE,QAAI,cAAc;AAElB,eAAW,SAAS,WAAW;AAC7B,UAAI,MAAM,OAAO,MAAM,GAAI;AAE3B,YAAM,UAAU,KAAK,kBAAkB,OAAO,KAAK;AACnD,YAAM,qBAAqB,KAAK,eAAe,IAAI,MAAM,EAAE;AAC3D,UAAI,oBAAoB;AACtB,uBAAe,UAAU,mBAAmB;AAAA,MAC9C;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,kBAAkB,GAAc,GAAsB;AACpD,UAAM,QAAQ,IAAI,IAAI,EAAE,gBAAgB,CAAA,CAAE;AAC1C,UAAM,QAAQ,IAAI,IAAI,EAAE,gBAAgB,CAAA,CAAE;AAE1C,QAAI,MAAM,SAAS,KAAK,MAAM,SAAS,GAAG;AAExC,aAAO,EAAE,SAAS,EAAE,OAAO,MAAM;AAAA,IACnC;AAEA,QAAI,UAAU;AACd,eAAW,OAAO,OAAO;AACvB,UAAI,MAAM,IAAI,GAAG,EAAG;AAAA,IACtB;AAGA,WAAO,UAAU,KAAK,IAAI,MAAM,MAAM,MAAM,IAAI;AAAA,EAClD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASQ,yBAA8C;AACpD,UAAM,+BAAe,IAAA;AACrB,eAAW,CAAC,IAAI,CAAC,KAAK,KAAK,gBAAgB;AACzC,eAAS,IAAI,IAAI,EAAE,kBAAkB;AAAA,IACvC;AACA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,aAAa,WAAyC;AAC5D,QAAI,WAAW;AAEf,eAAW,CAAC,IAAI,CAAC,KAAK,KAAK,gBAAgB;AACzC,YAAM,OAAO,UAAU,IAAI,EAAE,KAAK;AAClC,YAAM,QAAQ,KAAK,IAAI,EAAE,qBAAqB,IAAI;AAClD,iBAAW,KAAK,IAAI,UAAU,KAAK;AAAA,IACrC;AAEA,WAAO,WAAW,KAAK,OAAO;AAAA,EAChC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,wBAAgC;AAC9B,WAAO,CAAC,GAAG,KAAK,eAAe,OAAA,CAAQ,EAAE;AAAA,MACvC,CAAC,KAAK,MAAM,MAAM,EAAE;AAAA,MACpB;AAAA,IAAA;AAAA,EAEJ;AACF;AASO,SAAS,+BACd,QAC0B;AAC1B,SAAO,IAAI,yBAAyB,MAAM;AAC5C;AAKO,SAAS,sBACd,IACA,aACA,UAII,CAAA,GACE;AACN,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,sBAAsB,QAAQ,wBAAwB,CAAA;AAAA,IACtD,UAAU,QAAQ,YAAY;AAAA,IAC9B,YAAY,QAAQ,cAAc;AAAA,EAAA;AAEtC;"}