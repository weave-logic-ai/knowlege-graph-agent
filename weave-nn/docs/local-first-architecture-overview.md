---
visual:
  icon: üìö
icon: üìö
---
# Local-First Architecture Overview: The Neural Network Junction

**Date**: 2025-10-23
**Status**: Core Architecture Document
**Scope**: MVP - Local Loop Only

---

## üéØ Executive Summary

Weave-NN MVP implements **ONLY the local loop**‚Äîa closed-circuit knowledge system where multiple AI agents ("neural networks") connect through a shared knowledge graph, with **Weaver acting as the neural network junction point**.

### Core Principle

> **"Local First, Neural Junction, Knowledge Compound"**

We are building a **privacy-first, speed-first, ownership-first** system where:
- All data lives on your local machine (Obsidian vault)
- Multiple AI systems share knowledge without centralized coordination
- Each agent benefits from collective intelligence (compound learning)
- Weaver proxies all interactions, providing observability and durability

---

## üß† The Neural Network Junction Concept

### What is a "Neural Network Junction"?

Think of Weaver as a **railway junction** for AI systems:
- Multiple "train lines" (AI agents) converge at one point
- The junction (Weaver) directs traffic and coordinates movement
- Each train (agent) can access the shared depot (knowledge graph)
- No central control needed‚Äîlocal coordination through shared substrate

### Research Foundation

This architecture is based on peer-reviewed research:

**1. Key-Value Memory Networks** (Miller et al., 2016, EMNLP)
- Separated addressing (keys) from content (values)
- Multiple neural systems query shared external memory
- Sub-linear search time scales to thousands of nodes

**2. Federated Learning** (McMahan et al., 2017)
- Distributed AI systems learn from shared knowledge
- No centralized model training required
- Privacy-preserving collaborative intelligence

**3. Sparse Memory Finetuning** (2024, arXiv:2510.15103v1)
- Selective memory updates (10k-50k slots out of millions)
- TF-IDF-based parameter selection prevents interference
- New knowledge doesn't disrupt established patterns

**4. Memory-Augmented Neural Networks** (Weston et al., 2015, ICLR)
- Multi-hop retrieval through chained memory locations
- Semantic similarity search via hash-based indexing
- External memory augments AI without model retraining

**Key Insight**: Distributed AI systems benefit from a shared knowledge substrate without requiring centralized training or model merging. The knowledge graph acts as external memory that all agents can read and write.

---

## üìê Architecture Diagram

### MVP Local Loop

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        LOCAL MACHINE                             ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ           AI "Neural Networks" (Multiple Systems)         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Claude     ‚îÇ  ‚îÇClaude Flow  ‚îÇ  ‚îÇ   Future    ‚îÇ      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Code      ‚îÇ  ‚îÇ   Agents    ‚îÇ  ‚îÇLocal Models ‚îÇ      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                 ‚îÇ                 ‚îÇ             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                              ‚îÇ                                    ‚îÇ
‚îÇ                              ‚ñº                                    ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                    ‚îÇ                     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ   WEAVER PROXY      ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  (Neural Junction)  ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ                     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Webhook Router    ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Durable Workflows ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ State Management  ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Observability     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ                     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                               ‚îÇ                                   ‚îÇ
‚îÇ                               ‚ñº                                   ‚îÇ
‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ            ‚îÇ    Built-in Capabilities             ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ                                       ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ  ‚Ä¢ MCP Tools (@mcp/sdk)              ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ  ‚Ä¢ File Watcher (chokidar)           ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ  ‚Ä¢ Obsidian API Client (REST)        ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ  ‚Ä¢ Git Operations                    ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ  ‚Ä¢ File System Operations            ‚îÇ              ‚îÇ
‚îÇ            ‚îÇ                                       ‚îÇ              ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                           ‚îÇ                                       ‚îÇ
‚îÇ                           ‚ñº                                       ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ              ‚îÇ                            ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ   KNOWLEDGE GRAPH          ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ  (Obsidian Vault)          ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ                            ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ  ‚Ä¢ Markdown files          ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ  ‚Ä¢ YAML frontmatter (keys) ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ  ‚Ä¢ Wikilinks (connections) ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ  ‚Ä¢ Git version control     ‚îÇ                       ‚îÇ
‚îÇ              ‚îÇ                            ‚îÇ                       ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        ALL LOCAL ‚Ä¢ NO CLOUD ‚Ä¢ FULL PRIVACY ‚Ä¢ FULL OWNERSHIP

        SINGLE SERVICE: Just run `npm start` and everything works!
```

### Data Flow: The Local Loop

```
1. AI Agent (Claude) generates knowledge
   ‚Üì
2. Claude Code Hook ‚Üí Webhook POST to Weaver
   ‚Üì
3. Weaver Workflow (durable, observable)
   ‚Üì
4. Service Proxy (MCP/Obsidian API)
   ‚Üì
5. Knowledge Graph (Markdown + YAML)
   ‚Üì
6. File Watcher detects change
   ‚Üì
7. Weaver Workflow triggered
   ‚Üì
8. Update graph metadata (links, clusters, embeddings)
   ‚Üì
9. Agent retrieves context from graph (via MCP)
   ‚Üì
10. Enhanced agent execution (+10% success rate)
    ‚Üì
    [LOOP BACK TO STEP 1]
```

**This is a CLOSED LOOP**: Knowledge flows continuously, agents learn from each other's contributions, and the system gets smarter over time.

---

## üèóÔ∏è MVP Scope: What We're Building

### ‚úÖ IN SCOPE (MVP - Local Loop Only)

**Infrastructure**:
- ‚úÖ Obsidian vault (local markdown storage)
- ‚úÖ **Weaver (THE ONLY SERVICE - unified Node.js/TypeScript)**
  - MCP server (`@modelcontextprotocol/sdk`)
  - Workflow orchestration (`workflow.dev`)
  - File watcher (`chokidar` - monitors vault changes)
  - Webhook endpoints (`hono`)
  - Service proxies (Obsidian API, Git, File System)

> **Architecture Simplification**: Weaver is now the **ONLY service**. It serves triple roles as MCP server, workflow orchestrator, AND file watcher using `chokidar`. This reduces from 4 services ‚Üí **1 service** (75% reduction).

**Features**:
- ‚úÖ Task completion feedback loop
- ‚úÖ Knowledge graph auto-linking
- ‚úÖ Agent memory storage and retrieval
- ‚úÖ Workflow orchestration via Weaver
- ‚úÖ Real-time observability (traces)

**AI Systems Supported**:
- ‚úÖ Claude Code (via hooks ‚Üí webhooks)
- ‚úÖ Claude Flow agents (via MCP)
- ‚úÖ Future: Any AI system with webhook/API support

### ‚ùå OUT OF SCOPE (Post-MVP)

**NOT in MVP**:
- ‚ùå Web UI (Obsidian is the UI)
- ‚ùå Cloud storage (everything local)
- ‚ùå Multi-user collaboration (single user only)
- ‚ùå SaaS platform (local tool only)
- ‚ùå RabbitMQ message queue (Weaver handles async)
- ‚ùå Docker containers (simple Node.js + Python)
- ‚ùå Complex microservices (3 simple services)

### üîÆ Future (Post-MVP Considerations)

**If user needs grow**:
- Cloud sync (optional, via Git or Obsidian Sync)
- Web interface (optional, for visualization)
- Team collaboration (optional, via shared vault)
- RabbitMQ (if >3 services need pub/sub)
- Advanced analytics (optional, via visualization tools)

**MVP Philosophy**: Start simple, prove value, expand if needed.

---

## üî¨ Why This Architecture?

### 1. Privacy First

**Problem**: Cloud AI services = data leaves your machine
**Solution**: Local-first = all knowledge stays on your device

- No API calls to external services for knowledge retrieval
- Git-trackable history (who changed what, when)
- Encryption at rest (if desired, via LUKS/FileVault)
- No vendor lock-in (plain markdown files)

### 2. Speed First

**Problem**: Network latency kills productivity (100-500ms per API call)
**Solution**: Local memory = sub-millisecond retrieval

- Obsidian API: <5ms for file operations
- Shadow cache (SQLite): <1ms for metadata queries
- No network round trips for knowledge lookup
- Instant search across entire knowledge base

### 3. Ownership First

**Problem**: Cloud platforms control your data format and export
**Solution**: Plain markdown + Git = you own everything

- Human-readable markdown (no proprietary formats)
- Git version control (full history, branching, rollback)
- Easy backup (just copy files or push to Git)
- Future-proof (markdown will outlive any platform)

### 4. Compound Learning

**Problem**: Each AI conversation starts from zero context
**Solution**: Shared knowledge graph = agents learn from each other

**Example Workflow**:
1. Claude Code implements feature ‚Üí creates task log
2. File watcher detects new task log ‚Üí extracts learnings
3. Learnings stored in knowledge graph with embeddings
4. Next day: Different agent searches "authentication patterns"
5. Retrieves prior learnings ‚Üí avoids repeating mistakes
6. Implements better solution faster (+10% success rate)

**This is compound learning**: Each task makes future tasks easier.

---

## üîÑ How Weaver Enables the Local Loop

### Weaver's Three Roles

**1. Neural Network Junction**
- Routes requests from multiple AI systems
- Provides unified interface to knowledge graph
- Prevents race conditions with durable workflows
- Coordinates async operations without RabbitMQ

**2. Workflow Orchestrator**
- Executes long-running tasks (phase summaries, git commits)
- Automatic retries with exponential backoff
- State persistence across restarts
- Time-travel debugging (view workflow history)

**3. Observability Hub**
- Centralized logging (all events in one place)
- Distributed tracing (see full workflow execution)
- Metrics dashboard (task success rate, latency)
- Error aggregation (catch failures early)

### Why Weaver vs Alternatives?

| Feature | Bash Scripts | n8n | Weaver | Winner |
|---------|--------------|-----|--------|--------|
| **Setup** | 6 scripts, 978 LOC | Docker + DB | 1 Node.js service, ~300 LOC | Weaver |
| **Observability** | debug.log | Manual setup | Automatic traces | Weaver |
| **State** | Manual deferred tasks | Manual | Automatic durable workflows | Weaver |
| **Testing** | Hard | Hard | Standard Jest/Vitest | Weaver |
| **Neural Junction** | ‚ùå No | ‚ö†Ô∏è Complex | ‚úÖ Built-in | Weaver |

**Decision**: Weaver simplifies architecture while enabling neural junction pattern.

---

## üìä Expected Benefits (MVP)

### Technical Metrics

| Metric | Before | After (Projected) | Improvement |
|--------|--------|-------------------|-------------|
| **Setup Time** | ~1 day (bash + n8n + RabbitMQ) | ~2 hours (Weaver only) | 75% faster |
| **LOC** | 978 (bash scripts) | ~300 (TypeScript) | 69% reduction |
| **Services** | 4 (MCP, Watcher, n8n, RabbitMQ) | 1 (Weaver only) | 75% simpler |
| **Observability** | debug.log | Full traces + time-travel | üî• |
| **Agent Success Rate** | Baseline | +10% (via memory retrieval) | +10% |

### Developer Experience

**Before (Bash Scripts)**:
- üò∞ Complex interdependencies between 6 scripts
- üò∞ Manual deferred task execution
- üò∞ No visibility into failures
- üò∞ Hard to test and debug
- üò∞ Difficult to extend

**After (Weaver)**:
- ‚úÖ Single service with clear responsibilities
- ‚úÖ Automatic durable execution
- ‚úÖ Full observability with traces
- ‚úÖ Standard TypeScript testing
- ‚úÖ Easy to add new workflows

### Business Value

**Time Savings**:
- Setup: 6 hours saved (1 day ‚Üí 2 hours)
- Maintenance: ~2 hours/month ‚Üí ~30 min/month
- Debugging: 90% reduction with time-travel debugging
- Feature development: 75% faster with Weaver

**ROI Timeline**:
- **Month 1**: -4 hours (migration cost - setup savings)
- **Month 2**: +1.5 hours (maintenance savings)
- **Month 3+**: +2 hours/month (compound learning effects)
- **Year 1**: +20 hours saved

---

## üöÄ Implementation Roadmap

### Phase 0: Prerequisites (This Week)

**Tasks**:
- [ ] Install Node.js 20+
- [ ] Setup Weaver project (`npm init`)
- [ ] Install dependencies:
  - `workflow-dev` - Durable workflows
  - `hono` + `@hono/node-server` - Webhook server
  - `@modelcontextprotocol/sdk` - MCP server
  - `chokidar` - File watcher (replaces Python watchdog)
- [ ] Create basic webhook server (Hono)
- [ ] Add MCP server endpoints
- [ ] Add file watcher (chokidar monitors vault)
- [ ] Verify health endpoint works
- [ ] Test MCP connection from Claude Code
- [ ] Test file change detection

**Duration**: 3 hours
**Blocker**: None
**Note**: NO Python dependencies needed (chokidar replaces watchdog)

### Phase 1: Core Workflow (Week 1)

**Tasks**:
- [ ] Implement task completion workflow
- [ ] Connect Claude Code hooks to Weaver webhooks
- [ ] Create task log in knowledge graph
- [ ] Test end-to-end flow

**Duration**: 2-3 days
**Blocker**: Phase 0 complete

### Phase 2: Knowledge Graph Integration (Week 2)

**Tasks**:
- [ ] Implement MCP client in Weaver
- [ ] Add memory extraction from task logs
- [ ] Store learnings in knowledge graph
- [ ] Test memory retrieval

**Duration**: 2-3 days
**Blocker**: Phase 1 complete

### Phase 3: Observability (Week 3)

**Tasks**:
- [ ] Add structured logging
- [ ] Implement trace visualization
- [ ] Create metrics dashboard
- [ ] Add error alerting

**Duration**: 2-3 days
**Blocker**: Phase 2 complete

### Phase 4: Extensions (Week 4+)

**Tasks**:
- [ ] Add phase summary workflow
- [ ] Implement git auto-commit workflow
- [ ] Add file watcher integration
- [ ] Create workflow templates

**Duration**: 1-2 weeks
**Blocker**: Phase 3 complete

**Total MVP Timeline**: 4-6 weeks

---

## üéì Key Learnings & Principles

### Design Principles

1. **Local First**: All data on local machine, no cloud dependencies
2. **Neural Junction**: Weaver connects multiple AI systems to shared knowledge
3. **Durable by Default**: Workflows persist state, survive restarts
4. **Observable Always**: Full traces, time-travel debugging, metrics
5. **Simple First**: Start with 3 services, add complexity only if needed

### Architecture Decisions

**‚úÖ Weaver over n8n**: Simpler, code-first, native TypeScript
**‚úÖ No RabbitMQ for MVP**: Weaver's durable workflows handle async
**‚úÖ Local-only scope**: Prove value locally before considering cloud
**‚úÖ Obsidian as UI**: No need to build custom interface for MVP
**‚úÖ Git for version control**: Industry-standard, proven, reliable

### Anti-Patterns to Avoid

**‚ùå Don't**: Build web UI before proving local value
**‚ùå Don't**: Add RabbitMQ until >3 services need pub/sub
**‚ùå Don't**: Use Docker for local dev (adds complexity)
**‚ùå Don't**: Build custom visualization before Obsidian graph limits
**‚ùå Don't**: Centralize AI models (keep distributed with shared memory)

---

## üìö References & Further Reading

### Research Papers

1. **Miller, A., et al. (2016)**. Key-Value Memory Networks for Directly Reading Documents. *EMNLP*. [[research/memory-networks-research|Analysis]]

2. **Weston, J., et al. (2015)**. Memory Networks. *ICLR*. Foundational work on external memory for neural networks.

3. **Continual Learning via Sparse Memory Finetuning (2024)**. *arXiv:2510.15103v1*. [[research/papers/sparse-memory-finetuning-analysis|Analysis]]

4. **Memory Networks and Knowledge Graph Design: A Research Synthesis**. [[research/memory-networks-research|Full Document]]. Comprehensive analysis of 15+ papers on knowledge graph design for AI systems.

### Related Documentation

**Architecture**:
- [[weaver-proxy-architecture|Weaver Architecture]] - Detailed technical spec
- [[concept-map|Concept Map]] - System overview diagram
- [[architecture/api-layer|API Layer]] - Integration patterns

**Decisions**:
- [[decisions/technical/adopt-weaver-workflow-proxy|D-020: Adopt Weaver]] - Full ADR
- [[rabbitmq-deferral-summary|RabbitMQ Deferral]] - Why no message queue

**Planning**:
- [[_planning/phases/phase-0-pre-development-work|Phase 0 Tasks]] - Setup checklist
- [[_planning/phases/phase-6-tasks|Phase 6 Tasks]] - MVP implementation
- [[_planning/MASTER-PLAN|Master Plan]] - Complete roadmap

---

## ‚ùì FAQ

### Q: Why local-first instead of cloud?

**A**: Privacy, speed, and ownership. Cloud means:
- Your knowledge leaves your machine (privacy risk)
- Network latency for every query (100-500ms)
- Vendor controls data format and export (lock-in)

Local means:
- All data on your device (full privacy)
- Sub-millisecond queries (no network)
- Plain markdown + Git (full ownership)

### Q: Can I use this with other AI models?

**A**: Yes! The neural junction design means any AI system with webhook or API support can connect. Examples:
- ‚úÖ Claude Code (already supported)
- ‚úÖ Claude Flow agents (already supported)
- ‚úÖ Local LLMs (via API wrapper)
- ‚úÖ OpenAI API (via webhook)
- ‚úÖ Custom agents (via MCP or webhooks)

### Q: What if I outgrow local-only?

**A**: The architecture supports gradual expansion:
1. **Today**: Local loop (MVP)
2. **Later**: Add cloud sync (optional, via Git)
3. **Later**: Add web UI (optional, for visualization)
4. **Later**: Add team collaboration (optional, via shared vault)

The local loop always remains functional. Cloud is additive, not replacement.

### Q: How does this compare to RAG systems?

**A**: Similar but different:
- **RAG**: Retrieve context for single LLM query
- **Weave-NN**: Shared memory for multiple AI agents over time

RAG is stateless (each query independent). Weave-NN is stateful (agents learn from history).

### Q: What's the minimum hardware needed?

**A**: Very modest:
- **CPU**: Dual-core processor
- **RAM**: 4GB (8GB recommended)
- **Storage**: 1GB for software + space for your vault
- **OS**: Windows 10+, macOS 10.14+, Linux (Ubuntu 20.04+)

The system is lightweight by design.

---

## ‚úÖ Summary

**Weave-NN MVP = Local Loop + Neural Junction + Knowledge Compound**

We're building a **privacy-first, speed-first, ownership-first** system where:
- Multiple AI agents share knowledge through Weaver (neural junction)
- All data stays local (Obsidian vault)
- Agents learn from collective intelligence (compound learning)
- Simple architecture (3 services, ~300 LOC for Weaver)

**No cloud. No web UI. No complexity. Just local intelligence.**

Prove the value locally, then expand if needed.

---

**Document Version**: 1.0
**Last Updated**: 2025-10-23
**Status**: Core Architecture Reference
**Scope**: MVP - Local Loop Only
